{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO34q214LQy+v8kH9xKxzK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"id":"yzQyNZsAFfKt","executionInfo":{"status":"ok","timestamp":1714734308141,"user_tz":-330,"elapsed":443,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}}},"outputs":[],"source":["#import required packages/library\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers.legacy import Adam\n","from tensorflow.keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM"]},{"cell_type":"code","source":["mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n","\n","x_train = x_train/255\n","x_test = x_test/255\n","\n","print(\"x_train =\",x_train.shape)\n","print(\"y_train =\",y_train.shape)\n","print(\"x_test =\",x_test.shape)\n","print(\"y_test =\",y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwXmLhcZGOlX","executionInfo":{"status":"ok","timestamp":1714733800750,"user_tz":-330,"elapsed":933,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}},"outputId":"9a7dda15-24b4-4fa2-d366-95e9e6122864"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","x_train = (60000, 28, 28)\n","y_train = (60000,)\n","x_test = (10000, 28, 28)\n","y_test = (10000,)\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","\n","# IF you are running with a GPU, try out the CuDNNLSTM layer type instead (don't pass an activation, tanh is required)\n","model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n","model.add(Dropout(0.2))#when model is overfit droping 0.2 of 128 neuron\n","\n","#return_sequences= True   # This flag is used for when you're continuing on to another recurrent layer.\n","\n","model.add(LSTM(128, activation='relu'))\n","model.add(Dropout(0.1))\n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(10, activation='softmax')) #output layer 0-9 mnist model"],"metadata":{"id":"mmtuoUhJGRfZ","executionInfo":{"status":"ok","timestamp":1714733808776,"user_tz":-330,"elapsed":478,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wL2FMv4G1Vy","executionInfo":{"status":"ok","timestamp":1714733938296,"user_tz":-330,"elapsed":435,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}},"outputId":"8044b912-0db4-412d-aa6b-6596b9839b2c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 28, 128)           80384     \n","                                                                 \n"," dropout (Dropout)           (None, 28, 128)           0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 32)                4128      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 216426 (845.41 KB)\n","Trainable params: 216426 (845.41 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["opt = tf.keras.optimizers.legacy.Adam(lr=0.001, decay=1e-6)\n","\n","# Compile model\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZW3DqRaUG8hF","executionInfo":{"status":"ok","timestamp":1714734315307,"user_tz":-330,"elapsed":474,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}},"outputId":"13bc9d8f-4ee1-4fc9-bdb0-ab550b15cd46"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["model.fit(x_train,y_train,\n","          epochs=3,verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UyxQ3Ab-IYv-","executionInfo":{"status":"ok","timestamp":1714734785288,"user_tz":-330,"elapsed":444972,"user":{"displayName":"Parva Jain","userId":"14424518450825761591"}},"outputId":"0c465b1d-56f6-4701-b749-674ba5934155"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","1875/1875 [==============================] - 143s 75ms/step - loss: 0.6181 - accuracy: 0.8014\n","Epoch 2/3\n","1875/1875 [==============================] - 140s 75ms/step - loss: 0.1531 - accuracy: 0.9583\n","Epoch 3/3\n","1875/1875 [==============================] - 139s 74ms/step - loss: 0.1001 - accuracy: 0.9729\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f1ff8499a50>"]},"metadata":{},"execution_count":19}]}]}